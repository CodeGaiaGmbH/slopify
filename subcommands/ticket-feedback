#!/usr/bin/env -S uv run --script
# /// script
# dependencies = [
#    "llm",
#    "llm-anthropic",
#    "jira @ git+https://github.com/pycontribs/jira.git@3.10.1",
# ]
# ///

import sys
import llm
import utils


PROMPT_TEMPLATE = """
# Task
Make a detailed implementation plan.

# Project overview
```
{project_map}
```

## Ticket title
{title}

## Ticket description
```
{description}
```

# Notes
- Understand project conventions by reading files.
- Feel free to ask clarification questions.
"""


def askQuestions(questions: list[str]) -> list[str]:
    """Ask a list of question to the developer or product owner"""

    # LLM does this sometimes
    if isinstance(questions, str):
        questions = [questions]

    print()
    print()
    print("I have questions:")
    for question in questions:
        print("---")
        print(question)
    sys.exit(1)




def main():

    issue = utils.load_and_clone_issue()

    model = llm.get_model("claude-4-sonnet")

    prompt = PROMPT_TEMPLATE.format(
        project_map=utils.get_project_map(),
        title=issue.fields.summary,
        description=issue.fields.description.strip(" \n"),
    )

    for i in range(5):
        print(f"Prompting {i+1}/5", "...")
        response = model.chain(
            prompt,
            tools=[utils.readFile, askQuestions],
        )
        # Don't print out the plan
        response.text()
    print("All clear!")


if __name__ == "__main__":
    main()
