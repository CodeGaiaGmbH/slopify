#!/usr/bin/env -S uv run --script
# /// script
# dependencies = [
#    "llm",
#    "llm-anthropic",
#    "jira @ git+https://github.com/pycontribs/jira.git@3.10.1",
# ]
# ///

import sys
import llm
import utils
import json


PROMPT_TEMPLATE = """
# Task
Make a detailed implementation plan.

# Project overview
```
{project_map}
```

## Ticket title
{title}

## Ticket description
```
{description}
```

# Notes
- Understand project conventions by reading files.
- Feel free to ask clarification questions.
"""

QUESTIONS_TO_REQUIREMENTS_TEMPLATE = """
# Persona
You are a product and software expert with good taste.

# Task
Answer the given questions by understanding the project.

# Questions
{questions}

# Project overview
```
{project_map}
```
"""

# MODEL = "claude-4-sonnet"
MODEL = "claude-3.5-haiku"


def askQuestions(questions: str) -> str:
    """Ask questions to the developer or product owner."""
    print(f"askQuestions({questions})")
    raise llm.CancelToolCall()


def questions_to_requirements(questions):
    model = llm.get_model(MODEL)
    prompt = QUESTIONS_TO_REQUIREMENTS_TEMPLATE.format(
        project_map=utils.get_project_map(),
        questions=questions,
    )

    response = model.chain(
        prompt,
        tools=[utils.readFiles],
    )

    answers = response.text()
    print("ANSWERS:", answers)
    requirements = model.prompt(
        f"Reformulate to a list of one-sentence requirements:\n\n{answers}",
        schema=llm.schema_dsl("requirement", multi=True),
    )
    requirements_json = json.loads(requirements.text())
    return [i["requirement"] for i in requirements_json["items"]]


def main():

    issue = utils.load_and_clone_issue()

    model = llm.get_model(MODEL)

    prompt = PROMPT_TEMPLATE.format(
        project_map=utils.get_project_map(),
        title=issue.fields.summary,
        description=issue.fields.description.strip(" \n"),
    )

    for i in range(5):
        print(f"Prompting {i+1}/5", "...")
        conversation = model.conversation()
        response = conversation.chain(
            prompt,
            tools=[utils.readFiles, askQuestions],
        )
        # Don't print out the plan
        response.text()

        # Find the questions llm call
        questions = None
        for conversation in conversation.responses:
            for tc in conversation.tool_calls():
                if tc.name == "askQuestions":
                    questions = tc.arguments["questions"]
        if questions is None:
            print("askQuestions not called")
            continue
        break


    print("QUESTIONS:", questions)
    requirements = questions_to_requirements(questions)
    print("REQUIREMENTS:")
    for requirement in requirements:
        print(requirement)
        print()

    print("Updating description...")
    descr = issue.fields.description
    descr += "\n\n"
    for requirement in requirements:
        descr += f"* {requirement}\n"
    issue.update(description=descr)

    print("All clear!")


if __name__ == "__main__":
    main()
